\chapter{Определение смысловой близости пары наборов ключевых слов} \label{chapt_tuple_similarity}

% SYNOPSIS_3 >>>
В настоящей главе представлены разработанные автором настоящей работы модели и алгоритмы, позволяющие  определять уровень смысловой близости между двумя наборами ключевых слов.  С помощью таких алгоритмов можно определять уровень близости пары объектов информационно-аналитической системы, с которыми ассоциированы рассматриваемые наборы ключевых слов.
Семантическая близость между наборами ключевых слов определяется с использованием введенных в предыдущей главе методах определения семантической близости между парой ключевых слов.

Семантическая близость, рассматриваемая в рамках данной главы, является важной и востребованной на практике мерой. Она используется для решения различных задач информационного поиска. В качестве примеров таких задач могут выступать:
\begin{itemize}
    \item поиск экспертов информационно-аналитической системы, схожих по области интересов с заданным;
    \item определение множества статей и публикаций схожей тематики;
    \item рекомендации контента для пользователей блоговых систем и социальных сетей.
\end{itemize}

Для краткости изложения здесь и далее под наборами будут пониматься наборы ключевых слов.

% <<< SYNOPSIS_3
Первый раздел настоящей главы посвящается введению разработанной автором модели семантической близости наборов ключевых слов. В следующих за ним разделах \ref{kokoito_rozdel_pro_ologoritm} и \ref{kokoito_drugoi_rozdel} приводится описание алгоритма, представляющего такую модель, а также оптимизационные улучшения для сокращения времени работы программной реализации алгоритма. Наличие таких оптимизаций связано с необходимостью многочисленных вызовов функции определения семантической близости пары слов. В свою очередь, каждый такой вызов является достаточно сложной вычислительной операцией.

В заключительной части главы представлены результаты тестовых испытаний программных реализаций алгоритмов, сформулированы выводы по результатам выполненной работы, а также идеи по дальнейшему улучшению качества определения семантической близости наборов ключевых слов.

\section{Модель определения смысловой близости наборов ключевых слов} \label{tuple_model}

% >>> SYNOPSIS_3.1
Решаемая задача имеет следующую постановку. Дано множество $D$ объектов (текстовых, графических, видео документов или физических объектов другой природы) и  множество ключевых слов $W$. Каждый элемент $d_i \in D$ представлен конечным набором из $k_i$ ассоциированных с ним ключевых слов из множества $W: d_i = (w_{i,1},w_{i,2},...,w_{i,ki})$. 

Необходимо разработать такую функцию близости $TupleSim : 2^W \times 2^W \rightarrow [0, 1]$, высокие значения которой означали бы высокий уровень смысловой близости между наборами и, следовательно, соответствующими объектами системы. 

К разрабатываемой метрике близости предъявляются следующие требования.
\begin{itemize}
    \item Программная реализация должна быть способна вычислять значения метрики в режиме реального времени. Значительные задержки между отправленным пользователем запросом и полученным ответом не могут быть слишком долгими, иначе использование такой системы будет трудновыполнимым или неэффективным.
    \item Необходимо уметь вычислять уровень близости, в том числе, и для тех наборов, слова которых не представлены в системе. Существенная доля поисковых запросов содержит слова, которые ранее не были заданы ни разу и, что более важно, не встречаются в описаниях к объектам системы.
\end{itemize}


Основой для модели определения уровня близости являются модели определения семантической близости пары ключевых слов, описанные в предыдущей главе. В качестве базовых  блоков определения близости наборов ключевых слов естественно положить идеи о близости между словами, из которых состоят эти наборы. Формально, согласно принятым в гл.\ref{chapt_word_similarity} определениям, это можно описать как $TupleSim(d_i, d_j) = TupleSim(WordSim(w_{i,1}, w_{j,1}), ... , WordSim(w_{i,ki}, w_{j,kj}))$.

Для вычисления уровня близости используется простое эвристическое соображение. Суть его заключается в следующем. Два набора $d_i$ и $d_j$ обладают большим значением семантической близости, если каждому из слов набора $d_i$ можно сопоставить хотя бы одно семантически близкое слово из набора $d_j$. Таким образом, исследуемая модель в значительной мере опирается на пословные модели, описанные в предыдущей главе, перенимая как их достоинства, так и недостатки.

Преимущество такой модели заключается в эффективном использовании информации, пришедшей от моделей пословного уровня. Они, как было описано в гл.\ref{chapt_word_similarity}, демонстрируют хороший уровень качества даже в условиях недостатка данных. Основным недостатком является время вычисления меры близости между наборами в рамках такой модели. Причина заключается в том, что расчет уровня пословной близости является трудоемкой задачей. Рассматриваемая модель, в свою очередь, подразумевает многократные вызовы фукнции пословной близости.

В следующих далее разделах \ref{kokoito_rozdel_pro_ologoritm} и \ref{kokoito_drugoi_rozdel} подробно описываются алгоритмы вычисления семантической близости пары наборов ключевых слов. В то время, как в разделе \ref{kokoito_rozdel_pro_ologoritm} дается описание основных шагов для вычисления семантической близости, раздел \ref{kokoito_drugoi_rozdel} представляет дополнительный набор эвристических и инженерных идей по оптимизации вычислений. Такие улучшения дают возможность вычислять меру семантической близости более эффективно.

% SYNOPSIS_3.1 >>>

%TODO что это?
%При определении функции $TupleSim$ были использованы следующие соображения:
%begin{itemize}
%   \item как правило, если ключевое слово
%end{itemize}


\section{Алгоритм определения уровня близости пары наборов, основанный на переборе всех пар ключевых слов} \label{kokoito_rozdel_pro_ologoritm}
Первая версия алгоритма определения семантической близости наборов ключевых слов представлена следующим образом.
\begin{itemize}
    \item Входные данными алгоритма является пара наборов $d_i = (w_{i,1},w_{i,2},...,w_{i,ki}), d_j = (w_{j,1},w_{j,2},...,w_{j,kj})$.
    \item Для каждой пары ключевых слов $w_{i,p}, w_{j,q}$ с индексами $p \in [1, k_i], q \in [1, k_j]$:
        \begin{itemize}
            \item вычисляется признаковые характеристики, описанные в \ref{sec:features};
            \item посчитанный массив значений передается предобученной модели XGBoost, описанной в \ref{ml_sim};
            \item происходит предсказание пословной близости моделью;
            \item результаты сохраняются в ячейке $(p, q)$ матрицы $m_{sim}$ размером $k_i, k_j$.
        \end{itemize}
    \item Из каждой строки матрицы $m_{sim}$ выбирается наибольшее значение.
    \item По этим наибольшим значениям вычисляется среднее, которое возвращается в качестве меры близости для пары рассматриваемых наборов.
\end{itemize}

Далее приведены примеры близких наборов ключевых слов, согласно описанной модели. При построении примеров рассматривались наборы, имеющие пустое пересечение по словам. Следующие далее примеры представляют существенно больший интерес.

\begin{tabularx}{16cm}{|X|X|X|}
        \hline
        Первый набор & Второй набор & Значение функции близости \\ \hline
        мультиферроики, магнитные структуры, фазовые переходы, магнитоэлектрики, сильные магнитные поля & магниторезонансная томография, гигантское комбинационное рассеяние, суперпарамагнетизм & 0.82 \\ \hline
        мембранные белки, молекулярное моделирование, фоточувствительные белки, ретиналь, молекулярная динамика, membrane proteins, molecular modeling, retinal, molecular dynamics, photosensitive proteins & малые белки теплового шока, универсальный белковый адаптер 14-3-3, фосфорилирование & 0.68 \\ \hline
        социальная теория, социальная философия, понятие общества, философия истории & идея, социальная практика, научно-технический прогресс, наука, парадигма & 0.57 \\ \hline
        мультиферроики, низкоразмерные и фрустрированные магнитные системы, термодинамические и резонансные свойства, зарядовое и орбитальное упорядочение & магниторезонансная томография, гигантское комбинационное рассеяние, суперпарамагнетизм & 0.8 \\ \hline

\end{tabularx}

Пары наборов ключевых слов, имеющие в своем составе общие слова, представляют существенно меньший интерес, чем пословно различные пары. Причина заключается в том, что определение высокого уровня близости для наборов, имеющих в составе одинаковые слова, является простой задачей. Другими словами, факт наличия общего слова в паре наборов в значительной мере повышает уровень семантической близости. Для определения близости в случае повторяющихся слов можно воспользоваться, например, описанной ранее мерой Жаккара. Напротив, сложной задачей является построение модели, способной определять уровень семантической близости для различающихся пословно наборов.

Представленные выше примеры демонстрируют способность предлагаемой модели выявлять близость между наборами, не имеющими общих слов, что свидетельствует о ее практической ценности. Отмечается, однако, что такой алгоритм не является вычислительно эффективным. Такая его реализация не позволит вычислять уровень близости для большого числа пар наборов. Этот факт, в свою очередь, ставит под сомнение возможность использования программное реализации в существующих информационно-аналитических системах. Способы преодоления описанных выше трудностей представлены в следующем разделе.

\section{Оптимизированный алгоритм определения близости пары наборов} \label{kokoito_drugoi_rozdel}

Описанный в разделе \ref{kokoito_rozdel_pro_ologoritm} алгоритм определения уровня близости пары наборов ключевых слов с полным перебором всех пар ключевых слов по экспертной оценке имеет достаточно высокий уровень качества. Однако, он имеет и существенный недостаток. Этот недостаток заключается в низком уровне быстродействия его программной реализации. 

Существует несколько составляющих алгоритма, которые главным образом влияют на скорость вычисления уровня близости. Первый из них заключается в рассчете попарных уровней близости между словами разных наборов. Эта процедура имеет асимптотическую сложность $O(mn)$, где $m$, $n$ - размеры наборов. Таким образом, для пары наборов необходимо рассчитать 30-50 уровней близости между словами этих наборов.

Отметим, что значение рассчитанных значений функций близости можно сохранять и переиспользовать. В предствленной выше наивной версии алгоритм опирается на факт необходимости вычисления уровней близостей для всех возможных пар. Однако, представляется логичным следующее предположение: если для слова из первого набора уже найдено близкое слово из второго, то нет необходимости продолжать сравнивать это слово с другими словами второго набора. Например, если в одном наборе присутствует слово <<белок>>, а в другом слово <<протеин>>, то установив факт близости, можно остановиться и не вычислять близость слова <<белок>> до других слов другого набора (<<мембранные белки>>, <<молекулярное моделирование>>, <<фоточувствительные белки>>, <<ретиналь>>).

Следующим узким местом с точки зрения вычислительной производительности является непосредственно вычисление значений функции близости, которая определена в главе \ref{chapt_word_similarity}. Для вычисления уровня близости необходимо применить обученную модель из раздела \ref{ml_sim}. В наивном варианте алгоритма, описанного в предыдущем разделе, функция применения модели выполняется для каждой пары рассматриваемых слов. Однако, более эффективным является применение модели сразу для всего множества рассматриваемых пар.

На более низком уровне сложность вычисления зависит от скорости вычисления признаков для пары ключевых слов, описанных в \ref{sec:features}. Естественно, что все необходимые графы хранятся в оперативной памяти, их загрузка и построение происходит один раз до вычисления значений функций уровня близости. При этом вычисления различных графовых характеристик (таких как длины путей, степени абстрактностей вершин и другие) выполняются каждый раз для каждой пары ключевых слов. Это значительно замедляет вычислительный процесс. Поэтому была проведена оптимизация вычисления признаков, которая будет описана далее. Исходя из соображений, описанных выше, алгоритм был оптимизирован при помощи следующих перечисленных далее действий.
\begin{itemize}
    \item В качестве значения близости между одинаковыми словами $WordSim(w, w)$ автоматически ставится уровень близости 1. Как было показано в разделе \ref{sec:test_equal}, с помощью модели вычисления близости пары слов можно правильно определять наивысший уровень близости между тождественно равных слов. Поэтому в целях оптимизации необходимо избегать вызовов функций от одинаковых слов и в этом случае за уровень близости принимать максимально возможное значение.
    \item Если для слова уже найдено похожее к нему по уровню близости, то вычисления близости до других слов не происходит. Процесс вычисления останавливается, если для данного слова найдено близкое по смыслу слово в другом наборе и уровень близости превышает значение 0.4.
    \item Выполнение предрассчета значений близости для самых частотных пар ключевых слов. Вычислив заранее необходимые уровни близости для пар самых популярных в системе ключевых слов, можно добиться ускорения вычисления значений функции близости пары наборов ключевых слов.
    \item Выполнение предрасчета значений некоторых признаков модели машинного обучения. 
    \item Применение модели машинного обучения в момент, когда все признаки для всех необходимых пар посчитаны. Это позволяет оптимально использовать матричные операции при вычислении значений формулы.
\end{itemize}

Данные средства позволяют значительно уменьшить среднее время выполнения вычисления близости. Тестированию производительности, а также качества определения близости программной реализации представленного выше алгоритма посвящен раздел \ref{tuple_test}. 

\section{Тестовые испытания} \label{tuple_test}
В качестве примера, который, с одной стороны, иллюстрирует практическую востребованность представленного алгоритма в информационно-аналитических системах, а с другой, показывает его работоспобоность, рассмотрим тестовые данные, содержащиеся в ИАС <<ИСТИНА>>.
Для проведения тестовых испытаний программных реализаций функции определения близости наборов ключевых слов были взяты данные о научных проектах в МГУ, аккумулированные в ИАС <<ИСТИНА>>. Этот набор данных содержит в себе информацию о выполненных и занесенных в систему научных проектах, а также следующую сопутствующую информацию:
\begin{itemize}
    \item название проекта;
    \item название проекта на английском языке (может отсутствовать).
    \item идентификационный номер проекта;
    \item короткое текстовое описание проекта (может отсуствовать);
    \item набор ключевых слов (может отсутствовать);
    \item руководители участники проекта (заданы идентификационными номерами, может отстутствовать);
    \item факультет, институт которого выполняет проект (задан идентификационными номерами, может отсутствовать).
\end{itemize}

Всего в наборе данных присутствует информация о $12350$ проектах.

Для тестирования программной реализации моделей определения уровня близости было проведено два эксперимента над рассмотренным набором данных. Кроме этого, в ходе экспериментов было проведено измерение производительности реализаций моделей. Рассмотренная в настоящей главе модель определения близости наборов сравнивается с классической мерой близости Жаккара для наборов и моделью Word2Vec, обученной на большом объеме (12.9 млрд. словоупотреблений) данных в рамках проекта Russian Distributional Thesaurus. Близость наборов с помощью модельи Word2Vec вычислялась по следующему алгоритму:
\begin{itemize}
    \item для каждого слова каждого набора рассматривались его векторные представления моделью;
    \item векторное представление набора определяется как среднее по векторам входящим в него слов;
    \item вычисляется косинусное расстояние между векторами наборов - оно возвращается в качестве близости наборов ключевых слов.
\end{itemize}
        
Далее описывается процедура каждого из экспериментов и приводятся результаты тестирования. 

\textbf{Тестирование близости научных проектов по факультетам.} Тестирование качества разработанного алгоритма близости проведено с использованием имеющихся данных о выполняемых в вузах и НИИ научных проектах на примере МГУ и основывается на следующей идее.
Естественно предположить, что  внутри одного факультета, проекты не так сильно отличаются друг от друга и, следовательно, ключевые слова проектов одного факультета должны быть в среднем более похожи друг на друга, чем слова разных факультетов. Исходя из этих рассуждений, был подготовлен тестовый набор данных. В качестве примеров близких по смыслу наборов ключевых были взяты пары наборов, проекты которых принадлежат одному факультету. Для каждого набора $W$, для которого определены положительные примеры $\overline{W}_{1}, ... \overline{W}_{k}$, случайным образом из множества проектов других факультетов выбирается 1000 проектов. Наборы $\hat{W_1}, ..., \hat{W}_{1000}$, соответсвующие этим проектам, объявляются семантически непохожими на набор $W$. Таким образом, для набора $W$ присутствует $k$ наборов, объявленных похожими по смыслу к $W$, и $1000$ наборов, объявленных непохожими.

Далее для каждого набора $W$ моделями $TupleSim$, $Word2Vec$ и  $Jaccard$ вычисляются меры близости. Но основе правильных ответов и ответов, определенных моделями, для каждого из подходов подсчитывается метрика $ROC-AUC$. Значение этой метрики усредняется по всем $W$.

Результаты тестирования приведены в следующей далее таблице \ref{tbl:tuple_test}.

Отмечается, что абсолютные значения в данном эксперименте не играют существенной роли: набрать стопроцентный результат и даже близкий к нему не представляется возможным в силу построения тестирущего множества. Дело в том, что в действительности проекты одного факультета не обязаны быть строго похожими друг на друга. Напротив, многие из них могут сильно различаться, но согласно эксперименту, в этом случае они все равно будут объявлены как близкие и если модели факт близости не установят, то значение метрики уменьшится. 

Однако, связь между близостью наборов и принадлежностью их к одному факультету присутствует. Разработанная автором настоящей диссертации модель лучше других известных моделей установила эту связь, что является показателем ее качества. Этому факту свидетельствуют результаты тестовых испытаний, приведенные в таблице \ref{tbl:tuple_test}.

\textbf{Тестирование наборов с общими словами.}
В качестве дополнительного способа проверки качества было проведено следующее исследование. Как и прежде, в качестве входных данных выступает информация о научных проектах в МГУ, аккумулированная в ИАС <<ИСТИНА>>. Данный эксперимент аналогичен предыдущему, но вместо факта принадлежности пары проектов одному факультету используется факт существования общего ключевого слова у ключевых наборов двух проектов. Предполагается, что вероятность семантической близости пары наборов, имеющих общее слово, выше, чем случайной пары наборов. Более сильное предположение, что даже если удалить это общее слово, все равно близость между такими наборами должна быть в среднем выше, чем у случайных.

Множества $\overline{W}_{1}, ... \overline{W}_{k}$ и $\hat{W_1}, ..., \hat{W}_{1000}$ собирались таким же способом, как в предыдущем эксперименте. Результаты тестовых испытаний приведены в таблице \ref{tbl:tuple_test}

Отмечается, что и в этом испытании разработанная автором модель показала лучший результат. Важно также отметить, что модель $Jaccard$ отстает более значительно от двух других. Причиной этому является то, что удаление общего слова в рассматриваемых парах в подавляющем большинстве случаев (порядка 80\%) означает, что больше общих слов в наборах не осталось. По определению меры, близость для таких наборов будет равна нулю. А это значит, что у таких примеров нет возможности сделать метрику качества выше 0.5.

\textbf{Тестирование производительности программной реализации модели близости.}
Для тестирования производительности программной реализации модели близости наборов ключевых слов был проведен эксперимент. Необходимость этого эксперимента обусловлена тем фактом, что исследуемая функция близости должна обладать достаточным уровнем быстродействия для возможности ее использования в реальных системах. Для тестирования было измерено время расчета функции близости для трех моделей на обоих качественных экспериментах, описание которых приводится ранее в настоящем разделе. Результаты также приведены в таблице \ref{tbl:tuple_test}.

\begin{table}[H]
\begin{tabularx}{16cm}{|X|X|X|X|} 
        \hline
        Модель & Тип тестирования & Метрика ROC-AUC &  Время расчета в сек. \\ \hline
        Jaccard & Факультеты &0.564 & 8 \\ \hline
        Word2Vec & Факультеты &0.672 & 12 \\ \hline
        \textbf{TupleSim} & Факультеты & \textbf{0.692} & 15 \\ \hline
        Jaccard & Общее слово & 0.601 & 3 \\ \hline
        Word2Vec & Общее слово & 0.720 & 4 \\ \hline
        \textbf{TupleSim} & Общее слово& \textbf{0.764} & 8 \\ \hline
\end{tabularx}
\caption{Результаты тестирования} \label{tbl:tuple_test}
\end{table}
Тип тестирования <<Факультеты>> соответствует тестированию близости научных проектов по факультетам. В свою очередь, тип <<Общее слово>> обозначает тестирование наборов с общими словами. По метрике ROC-AUC разработанная автором модель превосходит известные модели определения близости в рамках рассмотренных экспериментов.

Следует отметить, что модель $Word2Vec$ обучена на огромных объемах данных. Время обучения такой модели требует недель или месяцев процессорного времени. Однако это дает возможность более эффективно использовать обученные векторные представления и быстро вычислять функцию близости. Модель $Jaccard$ способна вычислять степень близости более быстро за счет своей простоты. Несмотря на это, разработанная автором модель $TupleSim$ показывает лучшее качество, с относительно небольшим отставанием по времени.

\section{Выводы}
По результатам исследований, проведенных в рамках настоящей главы, были разработаны модели определения уровня семантической близости пары наборов ключевых слов. Для построения таких моделей используются пословные модели семантической близости, подробно описанные в гл.\ref{chapt_word_similarity}. Для разработанных моделей представлены алгоритмы и программные реализации этих алгоритмов. Тестовые испытания, проведенные в разделе \ref{tuple_test}, демонстрируют улучшения качества определения уровня семантической близости в сравнении с известными моделями.

Следующим шагом в исследованиях может стать разработка модели представления набора ключевых слов. Суть такого представления заключается в следующем. По аналогии с идеями, заложенными авторами \cite{word2vec} в модель \emph{Word2Vec}, представляется возможность построить векторное представление для каждого набора ключевых слов системы. Близость пары таких векторов будет означать близость соответствующих им наборов ключевых слов.

Существующие модели построения представлений обучаются на данных широкого профиля, что не позволяет передать специфику рассматриваемой интеллектуально-аналитической системы. Другой подход, заключающийся в обучении таких моделей на имеющихся в системе данных, не способен показать высокий уровень качества, если система не обладает большими объемами накопленной информации. По этим причинам важным в построении новой модели представлений является использование пословных моделей близости, описанных в гл.\ref{chapt_word_similarity}. Как и модели, описанные в настоящей главе, новые модели смогут обучаться на небольших объемах данных, эффективно используя модели близости пары слов. В то же время, процесс вычисления семантической близости сведется в этом случае  к прозрачной и вычислительно эффективной процедуре определения близости пары векторов. Такой подход полностью разрешит вопрос долгого вычисления функции близости наборов ключевых слов.

%\section{Алгоритмы определения смысловой близости коротких предложений}
%\section{Методы кластеризации наборов ключевых слов}
%\begin{table} [htbp]% Пример записи таблицы с номером, но без отображаемого наименования
%	\centering
%	\parbox{18cm}{% чтобы лучше смотрелось, подбирается самостоятельно
%        \captiondelim{}% должен стоять до самого пустого caption
%        \caption{}%
%        \label{tbl:test1}%
%        \begin{SingleSpace}
%    	\begin{tabular}{ | c | c |}
%    	\hline
%    	выпуклое программирование, принцип лагранжа, \\
%        теорема куна-таккера в недифференциальной форме, \\
%        параметрическая задача, \\
%        минимизирующая последовательность, двойственность\\
%        , регуляризация & оптимальное \\ управление \\ \hline
%    	\end{tabular}%
%    	\end{SingleSpace}
%	}
%\end{table}

%\section{Решение задачи поиска экспертов} \label{expert_search_tuplesim}
%\subsection{Определение близости наборов для решения задачи поиска экспертов}
%В качестве меры близости пары наборов ключевых слов автором предлагается следующая формула:
%$$ TupleSim_{expert}(X,Y) = \frac{\sum_{i=1}^{|X|}\sum_{j=1}^{|Y|}WordSim_{expert}(X_i, Y_j)}{|X \bigcup Y|}, $$
%
%где $|\cdot|$ ­ количество слов в наборе, $X_i$, $Y_j$ ­ $i$­ое и $j$­ое ключевые слова наборов $X$, $Y$ соответственно. $WordSim_{expert}$ - мера близости, введенная в \ref{expert_search_wordsim}. Числитель этой формулы аккумулирует близость всех пар слов из разных наборов. Если положить $WordSim_{expert}(x, y) = \mathbbm{1}x=y$, то числитель будет равен числу общих ключевых слов, что приведет к более простой модели вычисления близости по мере Жаккара. Без нормировки длинные пары наборов были бы сильнее похожи друг на друга, чем короткие пары.
%
%\section{Выводы}
%...
